{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Model with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Load libraries for data processing\n",
    "import pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "## Supervised learning.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scipy.io import loadmat \n",
    "\n",
    "# visualization\n",
    "import seaborn as sns \n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=loadmat('./mu_30_new.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Sun Oct 29 19:07:36 2023',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'mu_30': array([[-1.38971000e-01,  8.07940000e-02,  4.67550000e-02, ...,\n",
       "          3.08949880e+01,  7.56606660e+01,  2.00000000e+00],\n",
       "        [-1.14305000e-01,  2.10289000e-01,  1.64010000e-02, ...,\n",
       "          3.08949880e+01,  7.56421660e+01,  2.00000000e+00],\n",
       "        [ 1.87850000e-01,  2.45232000e-01, -3.83500000e-03, ...,\n",
       "          3.08949880e+01,  7.56668320e+01,  2.00000000e+00],\n",
       "        ...,\n",
       "        [-3.82520000e-02,  4.79070000e-02,  1.25651595e+02, ...,\n",
       "          0.00000000e+00,  7.54818400e+01,  2.00000000e+00],\n",
       "        [-7.52510000e-02, -4.66450000e-02,  1.25945017e+02, ...,\n",
       "          0.00000000e+00,  7.52290160e+01,  2.00000000e+00],\n",
       "        [-4.23630000e-02, -7.95320000e-02,  1.25955135e+02, ...,\n",
       "          0.00000000e+00,  7.52043510e+01,  2.00000000e+00]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'mu_30'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=xx['mu_30']\n",
    "df2=xx['mu_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df2[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4300, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4300,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.38971000e-01,  8.07940000e-02,  4.67550000e-02, ...,\n",
       "         8.10446970e+01,  3.10369250e+01,  3.08949880e+01],\n",
       "       [-1.14305000e-01,  2.10289000e-01,  1.64010000e-02, ...,\n",
       "         8.10532790e+01,  3.10842370e+01,  3.08949880e+01],\n",
       "       [ 1.87850000e-01,  2.45232000e-01, -3.83500000e-03, ...,\n",
       "         8.10618610e+01,  3.11315500e+01,  3.08949880e+01],\n",
       "       ...,\n",
       "       [-3.82520000e-02,  4.79070000e-02,  1.25651595e+02, ...,\n",
       "         9.33903910e+01,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-7.52510000e-02, -4.66450000e-02,  1.25945017e+02, ...,\n",
       "         9.33903910e+01,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-4.23630000e-02, -7.95320000e-02,  1.25955135e+02, ...,\n",
       "         9.33903910e+01,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2.0: 3138, 1.0: 1162}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "frequency = collections.Counter(y)\n",
    "print(dict(frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=4300, minmax=(array([-5.115273, -2.595432, -0.347847, -0.434947, 83.908095, 81.044697,\n",
       "       -1.324747, -2.649494]), array([  4.403624,   1.93072 , 136.133849, 132.731328,  95.285252,\n",
       "        93.39181 ,  31.178862,  32.92942 ])), mean=array([-2.29577500e-02, -1.25899693e-02,  7.20929507e+01,  6.31970632e+01,\n",
       "        9.30161488e+01,  9.09173183e+01,  9.53148713e+00,  1.03431146e+01]), variance=array([2.93862299e-01, 1.04557303e-01, 2.29999727e+03, 2.64418231e+03,\n",
       "       1.01269701e+01, 1.25568996e+01, 1.43500580e+02, 1.50276617e+02]), skewness=array([-0.42847107, -0.17616163, -0.10231038,  0.18436985, -1.29680758,\n",
       "       -1.29850505,  0.82581391,  0.65702063]), kurtosis=array([12.04181825,  5.70255427, -1.40829526, -1.640806  ,  0.48330822,\n",
       "        0.38795558, -0.95821393, -1.24106579]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.describe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the class labels from their original string representation (M and B) into integers\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Normalize the  data (center around 0 and scale to remove the variance).\n",
    "scaler =StandardScaler()\n",
    "Xs = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21403567,  0.28883223, -1.50244263, ..., -2.78638917,\n",
       "         1.79544442,  1.67670329],\n",
       "       [-0.16852877,  0.68935417, -1.50307563, ..., -2.78396704,\n",
       "         1.7993944 ,  1.67670329],\n",
       "       [ 0.38892436,  0.79743123, -1.50349763, ..., -2.78154491,\n",
       "         1.80334447,  1.67670329],\n",
       "       ...,\n",
       "       [-0.02821673,  0.18711428,  1.11690548, ...,  0.69798513,\n",
       "        -0.7957641 , -0.84383228],\n",
       "       [-0.09647709, -0.10533061,  1.12302446, ...,  0.69798513,\n",
       "        -0.7957641 , -0.84383228],\n",
       "       [-0.03580122, -0.20704855,  1.12323546, ...,  0.69798513,\n",
       "        -0.7957641 , -0.84383228]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the number of repeats for repeated k-fold cross-validation\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model with a given number of repeats\n",
    "clf = SVC(probability=True)\n",
    "def evaluate_model_acc(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    " \n",
    "def evaluate_model_apr(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='average_precision', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_f1(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_recall(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# configurations to test\n",
    "repeats = range(1,4)\n",
    "results_acc = list()\n",
    "results_apr = list()\n",
    "results_f1 = list()\n",
    "results_recall = list()\n",
    "\n",
    "for r in repeats:\n",
    "    # evaluate using a given number of repeats\n",
    "    scores_acc = evaluate_model_acc(Xs, y, r)\n",
    "    scores_apr = evaluate_model_apr(Xs, y, r)\n",
    "    scores_f1 = evaluate_model_f1(Xs, y, r)\n",
    "    scores_recall = evaluate_model_recall(Xs, y, r)\n",
    "    # summarize\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_acc), sem(scores_acc), std(scores_acc)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_apr), sem(scores_apr), std(scores_apr)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_f1), sem(scores_f1), std(scores_f1)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_recall), sem(scores_recall),std(scores_recall)))\n",
    "    # store\n",
    "    results_acc.append(scores_acc)\n",
    "    results_apr.append(scores_apr)\n",
    "    results_f1.append(scores_f1)\n",
    "    results_recall.append(scores_recall)\n",
    "# plot the results\n",
    "pyplot.boxplot(results_acc, labels=[str(r) for r in repeats], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[207, 142],\n",
       "       [ 37, 904]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(probability=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.3, random_state=2, stratify=y)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.59      0.70       349\n",
      "           1       0.86      0.96      0.91       941\n",
      "\n",
      "    accuracy                           0.86      1290\n",
      "   macro avg       0.86      0.78      0.80      1290\n",
      "weighted avg       0.86      0.86      0.85      1290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
