{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Model with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Load libraries for data processing\n",
    "import pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "## Supervised learning.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scipy.io import loadmat \n",
    "\n",
    "# visualization\n",
    "import seaborn as sns \n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=loadmat('./mu_30_new.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=xx['mu_30']\n",
    "df2=xx['mu_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[:,:8]\n",
    "y=df2[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4300, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4300,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the class labels from their original string representation (M and B) into integers\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Normalize the  data (center around 0 and scale to remove the variance).\n",
    "scaler =StandardScaler()\n",
    "Xs = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the number of repeats for repeated k-fold cross-validation\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model with a given number of repeats\n",
    "clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3, loss=\"huber\"))\n",
    "def evaluate_model_acc(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    " \n",
    "def evaluate_model_apr(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='average_precision', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_f1(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_recall(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# configurations to test\n",
    "repeats = range(1,4)\n",
    "results_acc = list()\n",
    "results_apr = list()\n",
    "results_f1 = list()\n",
    "results_recall = list()\n",
    "\n",
    "for r in repeats:\n",
    "    # evaluate using a given number of repeats\n",
    "    scores_acc = evaluate_model_acc(Xs, y, r)\n",
    "    scores_apr = evaluate_model_apr(Xs, y, r)\n",
    "    scores_f1 = evaluate_model_f1(Xs, y, r)\n",
    "    scores_recall = evaluate_model_recall(Xs, y, r)\n",
    "    # summarize\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_acc), sem(scores_acc), std(scores_acc)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_apr), sem(scores_apr), std(scores_apr)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_f1), sem(scores_f1), std(scores_f1)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_recall), sem(scores_recall),std(scores_recall)))\n",
    "    # store\n",
    "    results_acc.append(scores_acc)\n",
    "    results_apr.append(scores_apr)\n",
    "    results_f1.append(scores_f1)\n",
    "    results_recall.append(scores_recall)\n",
    "# plot the results\n",
    "pyplot.boxplot(results_acc, labels=[str(r) for r in repeats], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[181, 168],\n",
       "       [ 67, 874]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3, loss=\"huber\"))\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.3, random_state=2, stratify=y)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.52      0.61       349\n",
      "           1       0.84      0.93      0.88       941\n",
      "\n",
      "    accuracy                           0.82      1290\n",
      "   macro avg       0.78      0.72      0.74      1290\n",
      "weighted avg       0.81      0.82      0.81      1290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
