{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Model with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Load libraries for data processing\n",
    "import pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "## Supervised learning.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scipy.io import loadmat \n",
    "\n",
    "# visualization\n",
    "import seaborn as sns \n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=loadmat('./mu_60_new.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Sun Oct 29 19:23:43 2023',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'mu_60': array([[-1.97530000e-02,  1.44514000e-01,  2.65190000e-02, ...,\n",
       "          5.49296790e+01,  7.58764900e+01,  2.00000000e+00],\n",
       "        [-2.04746000e-01,  2.32410000e-02,  1.07463000e-01, ...,\n",
       "          5.48823670e+01,  7.56483330e+01,  1.00000000e+00],\n",
       "        [ 2.72124000e-01, -9.39210000e-02,  1.17581000e-01, ...,\n",
       "          5.49296790e+01,  7.59998190e+01,  2.00000000e+00],\n",
       "        ...,\n",
       "        [ 9.02400000e-03, -2.60900000e-02,  1.14258724e+02, ...,\n",
       "          0.00000000e+00,  7.53030130e+01,  1.00000000e+00],\n",
       "        [ 2.13560000e-02, -1.26808000e-01,  1.14400376e+02, ...,\n",
       "          0.00000000e+00,  7.55065050e+01,  1.00000000e+00],\n",
       "        [-5.67520000e-02, -9.59760000e-02,  1.14127190e+02, ...,\n",
       "          0.00000000e+00,  7.53831770e+01,  1.00000000e+00]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=xx['mu_60']\n",
    "df2=xx['mu_60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df2[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SelectKBest(f_classif, k=5).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the class labels from their original string representation (M and B) into integers\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Normalize the  data (center around 0 and scale to remove the variance).\n",
    "scaler =StandardScaler()\n",
    "Xs = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the number of repeats for repeated k-fold cross-validation\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model with a given number of repeats\n",
    "clf = SVC(probability=True)\n",
    "def evaluate_model_acc(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    " \n",
    "def evaluate_model_apr(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='average_precision', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_f1(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_recall(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# configurations to test\n",
    "repeats = range(1,4)\n",
    "results_acc = list()\n",
    "results_apr = list()\n",
    "results_f1 = list()\n",
    "results_recall = list()\n",
    "\n",
    "for r in repeats:\n",
    "    # evaluate using a given number of repeats\n",
    "    scores_acc = evaluate_model_acc(Xs, y, r)\n",
    "    scores_apr = evaluate_model_apr(Xs, y, r)\n",
    "    scores_f1 = evaluate_model_f1(Xs, y, r)\n",
    "    scores_recall = evaluate_model_recall(Xs, y, r)\n",
    "    # summarize\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_acc), sem(scores_acc), std(scores_acc)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_apr), sem(scores_apr), std(scores_apr)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_f1), sem(scores_f1), std(scores_f1)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_recall), sem(scores_recall),std(scores_recall)))\n",
    "    # store\n",
    "    results_acc.append(scores_acc)\n",
    "    results_apr.append(scores_apr)\n",
    "    results_f1.append(scores_f1)\n",
    "    results_recall.append(scores_recall)\n",
    "# plot the results\n",
    "pyplot.boxplot(results_acc, labels=[str(r) for r in repeats], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>mean=%.4f se=%.3f std=%.3f' % ( mean(scores_apr), sem(scores_apr), std(scores_apr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1875,   56],\n",
       "       [ 303,  136]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(probability=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.3, random_state=2, stratify=y)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      1931\n",
      "           1       0.71      0.31      0.43       439\n",
      "\n",
      "    accuracy                           0.85      2370\n",
      "   macro avg       0.78      0.64      0.67      2370\n",
      "weighted avg       0.83      0.85      0.82      2370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
