{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the needed module\n",
    "\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "import itertools\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from scipy.io import loadmat \n",
    "import pandas as pd\n",
    "plt.style.use('seaborn-poster')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=loadmat('./kw_60_new.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=xx['kw_60']\n",
    "df2=xx['kw_60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[36:,:8]\n",
    "y=df2[36:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 3622, 2.0: 2278}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "frequency = collections.Counter(y)\n",
    "print(dict(frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=5900, minmax=(array([-4.510964, -2.591321, -0.408555, -0.480317,  0.      ,  0.      ,\n",
       "       -1.608621, -1.088185]), array([   4.506398,    2.870071,  105.638187,  102.591137, 1916.244813,\n",
       "       1860.592673,   58.667358,   58.620045])), mean=array([-3.84279783e-02, -2.25902753e-02,  2.70724391e+01,  2.75988631e+01,\n",
       "        1.87836016e+03,  1.82313293e+03,  4.12907456e+01,  4.12458791e+01]), variance=array([3.14132936e-01, 1.58094953e-01, 9.74481115e+02, 9.09612804e+02,\n",
       "       2.21135432e+04, 2.08580338e+04, 3.34563816e+02, 3.38919853e+02]), skewness=array([ -0.18834484,   0.23415292,   0.8897713 ,   0.77731505,\n",
       "       -12.29599531, -12.27306311,  -0.98736203,  -0.99359037]), kurtosis=array([  6.51200711,   6.79761623,  -0.60175781,  -0.74247648,\n",
       "       152.38169914, 151.99866776,  -0.30640951,  -0.31036569]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.describe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide records in training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of samples in training set: %d, number of samples in test set: %d'%(len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(40, 40, 40),\n",
       "              max_iter=4000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(40, 40, 40),\n",
       "              max_iter=4000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(40, 40, 40),\n",
       "              max_iter=4000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize ANN classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(40,40,40), activation='logistic', max_iter = 4000)\n",
    "\n",
    "# Train the classifier with the traning data\n",
    "mlp.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.90      0.93      0.91      1087\n",
      "         2.0       0.88      0.84      0.86       683\n",
      "\n",
      "    accuracy                           0.89      1770\n",
      "   macro avg       0.89      0.89      0.89      1770\n",
      "weighted avg       0.89      0.89      0.89      1770\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict results from the test data\n",
    "predicted = mlp.predict(X_test_scaled)\n",
    "\n",
    "# plot the confusion matrix\n",
    "cm = confusion_matrix(y_test,predicted)\n",
    "print(classification_report(y_test, predicted))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(cm, cmap=plt.cm.Reds, alpha=0.3)\n",
    "for i in range(cm.shape[0]):\n",
    "     for j in range(cm.shape[1]):\n",
    "         ax.text(x=j, y=i,\n",
    "                s=cm[i, j], \n",
    "                va='center', ha='center')\n",
    "plt.xlabel('Predicted Values', )\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the number of repeats for repeated k-fold cross-validation\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model with a given number of repeats\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(40,40,40), activation='logistic', max_iter = 4000)\n",
    "\n",
    "def evaluate_model_acc(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(mlp, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    " \n",
    "def evaluate_model_apr(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(mlp, X, y, scoring='average_precision', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_f1(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(mlp, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_recall(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(mlp, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# configurations to test\n",
    "repeats = range(1,11)\n",
    "results_acc = list()\n",
    "results_apr = list()\n",
    "results_f1 = list()\n",
    "results_recall = list()\n",
    "\n",
    "for r in repeats:\n",
    "    # evaluate using a given number of repeats\n",
    "    scores_acc = evaluate_model_acc(X, y, r)\n",
    "    scores_apr = evaluate_model_apr(X, y, r)\n",
    "    scores_f1 = evaluate_model_f1(X, y, r)\n",
    "    scores_recall = evaluate_model_recall(X, y, r)\n",
    "    # summarize\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_acc), sem(scores_acc), std(scores_acc)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_apr), sem(scores_apr), std(scores_apr)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_f1), sem(scores_f1), std(scores_f1)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_recall), sem(scores_recall),std(scores_recall)))\n",
    "    # store\n",
    "    results_acc.append(scores_acc)\n",
    "    results_apr.append(scores_apr)\n",
    "    results_f1.append(scores_f1)\n",
    "    results_recall.append(scores_recall)\n",
    "# plot the results\n",
    "pyplot.boxplot(results_acc, labels=[str(r) for r in repeats], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A combination of under- and oversampling method using pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='majority')\n",
    "steps = [('u', under), ('o', over), ('model', mlp)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "\n",
    "# import libraries for evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy import mean\n",
    "\n",
    "# evaluate pipeline\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('ROC AUC score for the combined sampling method: %.3f' % score)\n",
    "\n",
    "\n",
    "def evaluate_model_acc(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_apr(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='average_precision', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_f1(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_recall(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# configurations to test\n",
    "repeats = range(1,11)\n",
    "pipe_res_acc = list()\n",
    "pipe_res_apr = list()\n",
    "pipe_res_f1 = list()\n",
    "pipe_res_recall = list()\n",
    "\n",
    "for r in repeats:\n",
    "    # evaluate using a given number of repeats\n",
    "    scores_acc = evaluate_model_acc(X, y, r)\n",
    "    scores_apr = evaluate_model_apr(X, y, r)\n",
    "    scores_f1 = evaluate_model_f1(X, y, r)\n",
    "    scores_recall = evaluate_model_recall(X, y, r)\n",
    "    # summarize\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_acc), sem(scores_acc), std(scores_acc)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_apr), sem(scores_apr), std(scores_apr)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_f1), sem(scores_f1), std(scores_f1)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_recall), sem(scores_recall),std(scores_recall)))\n",
    "    # store\n",
    "    pipe_res_acc.append(scores_acc)\n",
    "    pipe_res_apr.append(scores_apr)\n",
    "    pipe_res_f1.append(scores_f1)\n",
    "    pipe_res_recall.append(scores_recall)\n",
    "# plot the results\n",
    "pyplot.boxplot(pipe_res_acc, labels=[str(r) for r in repeats], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
