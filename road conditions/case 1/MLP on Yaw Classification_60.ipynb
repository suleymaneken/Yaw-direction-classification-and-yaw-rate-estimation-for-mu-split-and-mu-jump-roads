{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the needed module\n",
    "\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "import itertools\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from scipy.io import loadmat \n",
    "import pandas as pd\n",
    "plt.style.use('seaborn-poster')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=loadmat('./wk_60_new.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=xx['wk_60']\n",
    "df2=xx['wk_60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[:,:8]\n",
    "y=df2[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2.0: 2341, 1.0: 3459}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "frequency = collections.Counter(y)\n",
    "print(dict(frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=5800, minmax=(array([ -4.365025,  -2.761926,  -0.479381,  -0.480317, 223.347762,\n",
       "       214.258395,  -0.946248,  -0.756998]), array([  3.982252,   2.9934  , 144.845453, 138.963401, 264.224059,\n",
       "       254.587946,  55.308178,  55.308178])), mean=array([-3.87106036e-02, -1.64765402e-02,  4.54305433e+01,  4.37790899e+01,\n",
       "        2.52416648e+02,  2.43146508e+02,  2.53804762e+01,  2.50408631e+01]), variance=array([3.08525426e-01, 1.89500658e-01, 1.99882658e+03, 1.71070970e+03,\n",
       "       1.46389584e+02, 1.42495239e+02, 4.22934333e+02, 4.30118524e+02]), skewness=array([-0.01953457, -0.00362137,  0.8213939 ,  0.83141111, -0.85336484,\n",
       "       -0.88003076,  0.24276585,  0.25681889]), kurtosis=array([ 5.38556769,  4.08478802, -0.54861432, -0.38769935, -0.47382632,\n",
       "       -0.43712424, -1.41638493, -1.41975283]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.describe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide records in training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 4060, number of samples in test set: 1740\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples in training set: %d, number of samples in test set: %d'%(len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(40, 40, 40),\n",
       "              max_iter=4000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(40, 40, 40),\n",
       "              max_iter=4000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(40, 40, 40),\n",
       "              max_iter=4000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize ANN classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(40,40,40), activation='logistic', max_iter = 4000)\n",
    "\n",
    "# Train the classifier with the traning data\n",
    "mlp.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.75      0.74      0.75      1038\n",
      "         2.0       0.62      0.63      0.63       702\n",
      "\n",
      "    accuracy                           0.70      1740\n",
      "   macro avg       0.69      0.69      0.69      1740\n",
      "weighted avg       0.70      0.70      0.70      1740\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict results from the test data\n",
    "predicted = mlp.predict(X_test_scaled)\n",
    "\n",
    "# plot the confusion matrix\n",
    "cm = confusion_matrix(y_test,predicted)\n",
    "print(classification_report(y_test, predicted))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(cm, cmap=plt.cm.Reds, alpha=0.3)\n",
    "for i in range(cm.shape[0]):\n",
    "     for j in range(cm.shape[1]):\n",
    "         ax.text(x=j, y=i,\n",
    "                s=cm[i, j], \n",
    "                va='center', ha='center')\n",
    "plt.xlabel('Predicted Values', )\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the number of repeats for repeated k-fold cross-validation\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model with a given number of repeats\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(40,40,40), activation='logistic', max_iter = 4000)\n",
    "\n",
    "def evaluate_model_acc(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(mlp, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    " \n",
    "def evaluate_model_apr(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(mlp, X, y, scoring='average_precision', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_f1(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(mlp, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_recall(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(mlp, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# configurations to test\n",
    "repeats = range(1,11)\n",
    "results_acc = list()\n",
    "results_apr = list()\n",
    "results_f1 = list()\n",
    "results_recall = list()\n",
    "\n",
    "for r in repeats:\n",
    "    # evaluate using a given number of repeats\n",
    "    scores_acc = evaluate_model_acc(X, y, r)\n",
    "    scores_apr = evaluate_model_apr(X, y, r)\n",
    "    scores_f1 = evaluate_model_f1(X, y, r)\n",
    "    scores_recall = evaluate_model_recall(X, y, r)\n",
    "    # summarize\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_acc), sem(scores_acc), std(scores_acc)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_apr), sem(scores_apr), std(scores_apr)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_f1), sem(scores_f1), std(scores_f1)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_recall), sem(scores_recall),std(scores_recall)))\n",
    "    # store\n",
    "    results_acc.append(scores_acc)\n",
    "    results_apr.append(scores_apr)\n",
    "    results_f1.append(scores_f1)\n",
    "    results_recall.append(scores_recall)\n",
    "# plot the results\n",
    "pyplot.boxplot(results_acc, labels=[str(r) for r in repeats], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A combination of under- and oversampling method using pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='majority')\n",
    "steps = [('u', under), ('o', over), ('model', mlp)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "\n",
    "# import libraries for evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy import mean\n",
    "\n",
    "# evaluate pipeline\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('ROC AUC score for the combined sampling method: %.3f' % score)\n",
    "\n",
    "\n",
    "def evaluate_model_acc(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_apr(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='average_precision', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_f1(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_recall(X, y, repeats):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # create model\n",
    "    # model = LogisticRegression()\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# configurations to test\n",
    "repeats = range(1,11)\n",
    "pipe_res_acc = list()\n",
    "pipe_res_apr = list()\n",
    "pipe_res_f1 = list()\n",
    "pipe_res_recall = list()\n",
    "\n",
    "for r in repeats:\n",
    "    # evaluate using a given number of repeats\n",
    "    scores_acc = evaluate_model_acc(X, y, r)\n",
    "    scores_apr = evaluate_model_apr(X, y, r)\n",
    "    scores_f1 = evaluate_model_f1(X, y, r)\n",
    "    scores_recall = evaluate_model_recall(X, y, r)\n",
    "    # summarize\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_acc), sem(scores_acc), std(scores_acc)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_apr), sem(scores_apr), std(scores_apr)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_f1), sem(scores_f1), std(scores_f1)))\n",
    "    print('>%d mean=%.4f se=%.3f std=%.3f' % (r, mean(scores_recall), sem(scores_recall),std(scores_recall)))\n",
    "    # store\n",
    "    pipe_res_acc.append(scores_acc)\n",
    "    pipe_res_apr.append(scores_apr)\n",
    "    pipe_res_f1.append(scores_f1)\n",
    "    pipe_res_recall.append(scores_recall)\n",
    "# plot the results\n",
    "pyplot.boxplot(pipe_res_acc, labels=[str(r) for r in repeats], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
